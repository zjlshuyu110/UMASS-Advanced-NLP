{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6c-UlZmY_Gj",
        "outputId": "f28ea3f1-efaa-4c96-c880-0d3fde65e93c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr80hEZhYJgz",
        "outputId": "3f84f8e7-40ea-4688-e784-36161159fd91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers datasets accelerate evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding,\n",
        "    set_seed,\n",
        ")\n",
        "import evaluate\n"
      ],
      "metadata": {
        "id": "w4e-BT5yYT6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    # ✅ your MLM model\n",
        "    \"model_name_or_path\": \"mlm_bert_goemotions_finance\",\n",
        "\n",
        "    # ✅ paths to your financial data\n",
        "    # Option A: you already have train/val/test\n",
        "    \"train_file\": \"data/processed/fin_train.jsonl\",\n",
        "    \"val_file\":   \"data/processed/fin_val.jsonl\",\n",
        "    \"test_file\":  \"data/processed/fin_test.jsonl\",\n",
        "\n",
        "    # number of sentiment labels: 3 = [neg, neu, pos]\n",
        "    \"num_labels\": 3,\n",
        "\n",
        "    # training hyperparams\n",
        "    \"learning_rate\": 2e-5,\n",
        "    \"batch_size\": 16,\n",
        "    \"num_epochs\": 5,\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"warmup_ratio\": 0.06,\n",
        "    \"seed\": 42,\n",
        "\n",
        "    # where to save checkpoints\n",
        "    \"output_dir\": \"sft_financial_full\",\n",
        "}\n",
        "\n",
        "set_seed(config[\"seed\"])\n"
      ],
      "metadata": {
        "id": "tjFxfpkBYWOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_files = {\n",
        "    \"train\": config[\"train_file\"],\n",
        "    \"validation\": config[\"val_file\"],\n",
        "    \"test\": config[\"test_file\"],\n",
        "}\n",
        "\n",
        "raw_datasets = load_dataset(\n",
        "    \"json\",\n",
        "    data_files=data_files,\n",
        ")\n",
        "print(raw_datasets)\n",
        "print(raw_datasets[\"train\"][0])\n"
      ],
      "metadata": {
        "id": "veQqyl1oYdef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(config[\"model_name_or_path\"], use_fast=True)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    # `text` column -> tokenized inputs\n",
        "    result = tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=False,  # we'll pad dynamically in the data collator\n",
        "        max_length=256,\n",
        "    )\n",
        "    return result\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=[col for col in raw_datasets[\"train\"].column_names if col not in (\"text\", \"label\")],\n",
        ")\n",
        "print(tokenized_datasets)\n"
      ],
      "metadata": {
        "id": "EFVzxlNsYkKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    config[\"model_name_or_path\"],\n",
        "    num_labels=config[\"num_labels\"],\n",
        "    problem_type=\"single_label_classification\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "9BbflFzuYmK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "\n",
        "    metrics: Dict[str, Any] = {}\n",
        "    metrics[\"accuracy\"] = accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
        "    # macro F1\n",
        "    metrics[\"macro_f1\"] = f1_metric.compute(\n",
        "        predictions=preds,\n",
        "        references=labels,\n",
        "        average=\"macro\"\n",
        "    )[\"f1\"]\n",
        "    # weighted F1\n",
        "    metrics[\"weighted_f1\"] = f1_metric.compute(\n",
        "        predictions=preds,\n",
        "        references=labels,\n",
        "        average=\"weighted\"\n",
        "    )[\"f1\"]\n",
        "\n",
        "    return metrics\n"
      ],
      "metadata": {
        "id": "mZbR94VTYuvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=config[\"output_dir\"],\n",
        "    learning_rate=config[\"learning_rate\"],\n",
        "    per_device_train_batch_size=config[\"batch_size\"],\n",
        "    per_device_eval_batch_size=config[\"batch_size\"],\n",
        "    num_train_epochs=config[\"num_epochs\"],\n",
        "    weight_decay=config[\"weight_decay\"],\n",
        "    warmup_ratio=config[\"warmup_ratio\"],\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"macro_f1\",\n",
        "    greater_is_better=True,\n",
        "    report_to=\"none\",  # set to \"wandb\" or \"tensorboard\" if you want logging\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ],
      "metadata": {
        "id": "BT8-mr80YvVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train()\n",
        "trainer.save_model(config[\"output_dir\"])\n",
        "tokenizer.save_pretrained(config[\"output_dir\"])\n",
        "\n",
        "print(\"Training done.\")\n",
        "print(\"Final train metrics:\", train_result.metrics)\n",
        "\n",
        "# Evaluate on validation after training\n",
        "val_metrics = trainer.evaluate(eval_dataset=tokenized_datasets[\"validation\"])\n",
        "print(\"Validation metrics:\", val_metrics)\n"
      ],
      "metadata": {
        "id": "9xW_np-YYxu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n",
        "print(\"Test metrics (financial):\")\n",
        "for k, v in test_metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "id": "oFZvL4FpY4dx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}