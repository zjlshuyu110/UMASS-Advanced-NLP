{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyMd2KV5N4HqyjRq5KZpEMCK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import accuracy_score, f1_score\n","from statsmodels.stats.contingency_tables import mcnemar\n","\n","LABELS_PATH = \"/content/drive/Shareddrives/cs685/preds/labels_mixed_test7.npy\"\n","\n","PRED_A_PATH = \"/content/drive/Shareddrives/cs685/preds/preds_sft4_domain_tokens_mixed_test4.npy\"\n","PRED_B_PATH = \"/content/drive/Shareddrives/cs685/preds/preds_sft7_lora_fixed_merged_mixed_test7.npy\"\n","\n","y = np.load(LABELS_PATH)\n","pa = np.load(PRED_A_PATH)\n","pb = np.load(PRED_B_PATH)\n","\n","assert len(y) == len(pa) == len(pb)\n","\n","# ---- Report metrics for both ----\n","def report(name, pred):\n","    return {\n","        \"acc\": accuracy_score(y, pred),\n","        \"macro\": f1_score(y, pred, average=\"macro\"),\n","        \"weighted\": f1_score(y, pred, average=\"weighted\"),\n","    }\n","\n","A = report(\"A\", pa)\n","B = report(\"B\", pb)\n","print(\"A:\", A)\n","print(\"B:\", B)\n","print(\"ΔAcc   :\", A[\"acc\"] - B[\"acc\"])\n","print(\"ΔMacro :\", A[\"macro\"] - B[\"macro\"])\n","\n","# ---- McNemar (paired) for Accuracy ----\n","a_correct = (pa == y)\n","b_correct = (pb == y)\n","b = np.sum(a_correct & ~b_correct)  # A right, B wrong\n","c = np.sum(~a_correct & b_correct)  # A wrong, B right\n","table = [[0, b],\n","         [c, 0]]\n","res = mcnemar(table, exact=True)\n","print(f\"McNemar exact: b={b}, c={c}, p={res.pvalue:.4g}\")\n","\n","# ---- Paired bootstrap for ΔAccuracy and ΔMacro-F1 ----\n","def paired_bootstrap(y_true, pred_a, pred_b, B=10000, seed=42):\n","    rng = np.random.default_rng(seed)\n","    n = len(y_true)\n","    diffs_acc = np.empty(B)\n","    diffs_f1  = np.empty(B)\n","\n","    for i in range(B):\n","        idx = rng.integers(0, n, size=n)\n","        yt = y_true[idx]\n","        pa_ = pred_a[idx]\n","        pb_ = pred_b[idx]\n","        diffs_acc[i] = accuracy_score(yt, pa_) - accuracy_score(yt, pb_)\n","        diffs_f1[i]  = f1_score(yt, pa_, average=\"macro\") - f1_score(yt, pb_, average=\"macro\")\n","\n","    ci_acc = (np.quantile(diffs_acc, 0.025), np.quantile(diffs_acc, 0.975))\n","    ci_f1  = (np.quantile(diffs_f1,  0.025), np.quantile(diffs_f1,  0.975))\n","    return ci_acc, ci_f1\n","\n","ci_acc, ci_f1 = paired_bootstrap(y, pa, pb, B=10000)\n","print(\"Bootstrap 95% CI for ΔAcc  :\", ci_acc)\n","print(\"Bootstrap 95% CI for ΔMacro:\", ci_f1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j-H8_F_SYkVR","executionInfo":{"status":"ok","timestamp":1765959780501,"user_tz":600,"elapsed":36327,"user":{"displayName":"Isaac Zhong","userId":"16182262700273782623"}},"outputId":"f27d6295-d588-4f3b-873b-e45f4194fd53"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["A: {'acc': 0.64499659632403, 'macro': 0.6372314136208436, 'weighted': 0.645966614283667}\n","B: {'acc': 0.6249149081007488, 'macro': 0.6177390837235109, 'weighted': 0.6269296773032487}\n","ΔAcc   : 0.020081688223281158\n","ΔMacro : 0.019492329897332628\n","McNemar exact: b=324, c=265, p=0.01678\n","Bootstrap 95% CI for ΔAcc  : (np.float64(0.0037440435670524908), np.float64(0.036427842069434925))\n","Bootstrap 95% CI for ΔMacro: (np.float64(0.003254709501336876), np.float64(0.03597877149775931))\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"riGYMn-hUsLl","executionInfo":{"status":"ok","timestamp":1765959219839,"user_tz":600,"elapsed":7,"user":{"displayName":"Isaac Zhong","userId":"16182262700273782623"}},"outputId":"d251c245-0033-4b67-ee0c-5417fd25adc7"},"outputs":[{"output_type":"stream","name":"stdout","text":["zero shot for sft4 accuacy confidence interval (0.5714830755873965, 0.5987861031971597)\n"]}],"source":["import math\n","\n","def wilson_ci(k, n, z=1.96):\n","    # k correct out of n\n","    if n == 0:\n","        return (0.0, 0.0)\n","    p = k / n\n","    denom = 1 + (z**2)/n\n","    center = (p + (z**2)/(2*n)) / denom\n","    half = (z * math.sqrt((p*(1-p) + (z**2)/(4*n)) / n)) / denom\n","    return center - half, center + half\n","\n","# Example: if N=5000 and acc=0.5852\n","n = 5000\n","k = round(0.5852 * n)\n","print(f\"zero shot for sft4 accuacy confidence interval {wilson_ci(k, n)}\")"]},{"cell_type":"code","source":["import math\n","\n","def wilson_ci(k, n, z=1.96):\n","    # k correct out of n\n","    if n == 0:\n","        return (0.0, 0.0)\n","    p = k / n\n","    denom = 1 + (z**2)/n\n","    center = (p + (z**2)/(2*n)) / denom\n","    half = (z * math.sqrt((p*(1-p) + (z**2)/(4*n)) / n)) / denom\n","    return center - half, center + half\n","\n","# Example: if N=5000 and acc=0.5852\n","n = 5000\n","k = round(0.5486 * n)\n","print(f\"zero shot for sft7 accuacy confidence interval {wilson_ci(k, n)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CPRZW-ZVUyTQ","executionInfo":{"status":"ok","timestamp":1765959219884,"user_tz":600,"elapsed":9,"user":{"displayName":"Isaac Zhong","userId":"16182262700273782623"}},"outputId":"28ebe4c1-1bb9-4b67-9c04-6f31cce50873"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["zero shot for sft7 accuacy confidence interval (0.5347742664084661, 0.5623511102221609)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WH0B1V1GXN-_","executionInfo":{"status":"ok","timestamp":1765959469153,"user_tz":600,"elapsed":20328,"user":{"displayName":"Isaac Zhong","userId":"16182262700273782623"}},"outputId":"338b117d-e49b-4092-8825-dacb615920e5"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip -q install transformers datasets accelerate scikit-learn statsmodels\n","\n","import json\n","import numpy as np\n","from pathlib import Path\n","from sklearn.metrics import accuracy_score, f1_score\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","\n","MODEL_DIR = \"/content/drive/MyDrive/models/sft4_domain_tokens\"\n","TEST_PATH = \"/content/drive/Shareddrives/cs685/final_data_SFT/label_mixed_3_test.jsonl\"\n","\n","# -------- Load JSONL test set --------\n","texts, labels = [], []\n","with open(TEST_PATH, \"r\", encoding=\"utf-8\") as f:\n","    for line in f:\n","        ex = json.loads(line)\n","        texts.append(ex[\"text\"])\n","        labels.append(int(ex[\"label\"]))\n","labels = np.array(labels)\n","\n","# -------- Load model/tokenizer --------\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","tok = AutoTokenizer.from_pretrained(MODEL_DIR, use_fast=True)\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR).to(device)\n","model.eval()\n","\n","# -------- Batched inference --------\n","def predict(texts, batch_size=32, max_len=256):\n","    preds = []\n","    for i in range(0, len(texts), batch_size):\n","        batch = texts[i:i+batch_size]\n","        inputs = tok(\n","            batch,\n","            truncation=True,\n","            padding=True,\n","            max_length=max_len,\n","            return_tensors=\"pt\",\n","        ).to(device)\n","        with torch.no_grad():\n","            logits = model(**inputs).logits\n","        preds.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n","    return np.array(preds)\n","\n","preds = predict(texts, batch_size=32)\n","\n","# -------- Metrics --------\n","acc = accuracy_score(labels, preds)\n","macro = f1_score(labels, preds, average=\"macro\")\n","weighted = f1_score(labels, preds, average=\"weighted\")\n","print(\"N =\", len(labels))\n","print(\"Accuracy   :\", acc)\n","print(\"Macro F1   :\", macro)\n","print(\"Weighted F1:\", weighted)\n","\n","# -------- Save predictions (paired testing later) --------\n","OUT_DIR = \"/content/drive/Shareddrives/cs685/preds\"\n","Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n","\n","out_path = f\"{OUT_DIR}/preds_{Path(MODEL_DIR).name}_mixed_test4.npy\"\n","np.save(out_path, preds)\n","np.save(f\"{OUT_DIR}/labels_mixed_test4.npy\", labels)\n","print(\"Saved:\", out_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4REOErUEXMP3","executionInfo":{"status":"ok","timestamp":1765959315257,"user_tz":600,"elapsed":71447,"user":{"displayName":"Isaac Zhong","userId":"16182262700273782623"}},"outputId":"64f4ee20-9a0e-4120-b022-ee08adf5a7dc"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["N = 2938\n","Accuracy   : 0.64499659632403\n","Macro F1   : 0.6372314136208436\n","Weighted F1: 0.645966614283667\n","Saved: /content/drive/Shareddrives/cs685/preds/preds_sft4_domain_tokens_mixed_test4.npy\n"]}]},{"cell_type":"code","source":["import json\n","import numpy as np\n","from pathlib import Path\n","from sklearn.metrics import accuracy_score, f1_score\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","\n","MODEL_DIR = \"/content/drive/MyDrive/models/sft7_lora_fixed_merged\"\n","TEST_PATH = \"/content/drive/Shareddrives/cs685/final_data_SFT/label_mixed_3_test.jsonl\"\n","\n","# -------- Load JSONL test set --------\n","texts, labels = [], []\n","with open(TEST_PATH, \"r\", encoding=\"utf-8\") as f:\n","    for line in f:\n","        ex = json.loads(line)\n","        texts.append(ex[\"text\"])\n","        labels.append(int(ex[\"label\"]))\n","labels = np.array(labels)\n","\n","# -------- Load model/tokenizer --------\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","tok = AutoTokenizer.from_pretrained(MODEL_DIR, use_fast=True)\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR).to(device)\n","model.eval()\n","\n","# -------- Batched inference --------\n","def predict(texts, batch_size=32, max_len=256):\n","    preds = []\n","    for i in range(0, len(texts), batch_size):\n","        batch = texts[i:i+batch_size]\n","        inputs = tok(\n","            batch,\n","            truncation=True,\n","            padding=True,\n","            max_length=max_len,\n","            return_tensors=\"pt\",\n","        ).to(device)\n","        with torch.no_grad():\n","            logits = model(**inputs).logits\n","        preds.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n","    return np.array(preds)\n","\n","preds = predict(texts, batch_size=32)\n","\n","# -------- Metrics --------\n","acc = accuracy_score(labels, preds)\n","macro = f1_score(labels, preds, average=\"macro\")\n","weighted = f1_score(labels, preds, average=\"weighted\")\n","print(\"N =\", len(labels))\n","print(\"Accuracy   :\", acc)\n","print(\"Macro F1   :\", macro)\n","print(\"Weighted F1:\", weighted)\n","\n","# -------- Save predictions (paired testing later) --------\n","OUT_DIR = \"/content/drive/Shareddrives/cs685/preds\"\n","Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n","\n","out_path = f\"{OUT_DIR}/preds_{Path(MODEL_DIR).name}_mixed_test7.npy\"\n","np.save(out_path, preds)\n","np.save(f\"{OUT_DIR}/labels_mixed_test7.npy\", labels)\n","print(\"Saved:\", out_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ialc2LOwXjCk","executionInfo":{"status":"ok","timestamp":1765959352998,"user_tz":600,"elapsed":37747,"user":{"displayName":"Isaac Zhong","userId":"16182262700273782623"}},"outputId":"19006200-9965-4b6e-a886-330ce12c5927"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["N = 2938\n","Accuracy   : 0.6249149081007488\n","Macro F1   : 0.6177390837235109\n","Weighted F1: 0.6269296773032487\n","Saved: /content/drive/Shareddrives/cs685/preds/preds_sft7_lora_fixed_merged_mixed_test7.npy\n"]}]}]}